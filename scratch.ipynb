{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T15:24:49.778039Z",
     "start_time": "2024-03-06T15:24:49.006145Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "df = pd.read_csv('Crimes_-_Map.csv')\n",
    "def calculate_r_squared(dataframe, x_idx, y_idx):\n",
    "\n",
    "    x_mean = dataframe.iloc[:, x_idx].mean()\n",
    "    y_mean = dataframe.iloc[:, y_idx].mean()\n",
    "\n",
    "    # This calculates the S_xx and S_yy. I\n",
    "    x_variance = pd.Series([])\n",
    "    y_variance = pd.Series([])\n",
    "    for i in range(dataframe.shape[0]):\n",
    "        x_variance.append((dataframe.iloc[i, x_idx] - x_mean) ** 2)\n",
    "    for i in range(dataframe.shape[0]):\n",
    "        y_variance.append((dataframe.iloc[i, y_idx] - y_mean) ** 2)\n",
    "\n",
    "    # Calculate the S_xy\n",
    "    covariance = pd.Series([])\n",
    "    for i in range(dataframe.shape[0]):\n",
    "        covariance.append((dataframe.iloc[i, x_idx] - x_mean) * (dataframe.iloc[i, y_idx] - y_mean))\n",
    "\n",
    "    # This calculates the sums for the S_xx, S_yy and S_xy columns\n",
    "    s_xx_sum = x_variance.sum()\n",
    "    s_yy_sum = y_variance.sum()\n",
    "    s_xy_sum = covariance.sum()\n",
    "\n",
    "    # This finds the r and r squared values\n",
    "    r = s_xy_sum / (math.sqrt(s_xx_sum) * math.sqrt(s_yy_sum))\n",
    "    r_squared = r ** 2\n",
    "    return r_squared"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Clean up some data to make the datasets work together.\n",
    "df = df.drop(df[df['BEAT'] == 1651].index)\n",
    "df = df.drop(df[df['BEAT'] == 1654].index)\n",
    "df = df.drop(df[df['BEAT'] == 1655].index)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T15:24:53.977258Z",
     "start_time": "2024-03-06T15:24:53.885332Z"
    }
   },
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T15:24:55.610524Z",
     "start_time": "2024-03-06T15:24:55.580791Z"
    }
   },
   "outputs": [],
   "source": [
    "df_arrests = df[df[\"ARREST\"] == \"Y\"]\n",
    "# Here we can see the top 10 beats with the most arrests made. The top beat is 1834 which is the beat that includes navy pier. I don't usually think of navy pier as a place with a lot of crime, but I guess I was wrong. \n",
    "# I used https://www.chicagocityscape.com/maps/index.php#/?places_type=chipolicebeat&search_term=1831 to find out where the beats are located\n",
    "arrests_per_beat = df_arrests['BEAT'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "BEAT\n632     5\n623     4\n921     3\n333     3\n1032    3\n       ..\n1722    1\n714     1\n2013    1\n913     1\n323     1\nName: count, Length: 98, dtype: int64"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's find if we get similar values when we limit the crimes only to murders\n",
    "df_murders = df_arrests.loc[df_arrests[\" PRIMARY_DESCRIPTION\"] == \"HOMICIDE\"]\n",
    "df_murders['BEAT'].value_counts().sort_values(ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T15:24:57.478284Z",
     "start_time": "2024-03-06T15:24:57.467639Z"
    }
   },
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "BEAT\n111     298\n112     184\n113       7\n114       6\n121       3\n       ... \n2531      8\n2532      3\n2533     36\n2534      3\n2535      4\nName: count, Length: 242, dtype: int64"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's find if we get similar values when we limit the crimes only to thefts\n",
    "df_thefts = df_arrests.loc[df_arrests[\" PRIMARY_DESCRIPTION\"] == \"THEFT\"]\n",
    "df_thefts['BEAT'].value_counts().sort_index(ascending= True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T15:25:01.457641Z",
     "start_time": "2024-03-06T15:25:01.445931Z"
    }
   },
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Let's take a look at some demographic data to see if we can find any correlations\n",
    "demo = pd.read_csv(\"master.csv\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T15:25:07.200288Z",
     "start_time": "2024-03-06T15:25:07.193048Z"
    }
   },
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/xb/xsgcqz1x6p341mp77shkwqlm0000gn/T/ipykernel_1077/835411764.py\u001B[0m in \u001B[0;36m?\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# This is the function that we will use to calculate the r squared value for the data.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;31m# It uses index column 0 and x and 1 as y where we use x to predict y.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;31m# the function goes calculate_r_squared(dataframe, x_idx, y_idx) where x_idx and y_idx are the index of the columns\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;31m# that we want to use to calculate the r squared value.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m \u001B[0mcalculate_r_squared2\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdemo\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/var/folders/xb/xsgcqz1x6p341mp77shkwqlm0000gn/T/ipykernel_1077/1152129344.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(dataframe, x_idx, y_idx)\u001B[0m\n\u001B[1;32m      9\u001B[0m     \u001B[0;31m# This calculates the S_xx and S_yy. I\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m     \u001B[0mx_variance\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mSeries\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m     \u001B[0my_variance\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mSeries\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdataframe\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 13\u001B[0;31m         \u001B[0mx_variance\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdataframe\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0miloc\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx_idx\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mx_mean\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m**\u001B[0m \u001B[0;36m2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     14\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdataframe\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     15\u001B[0m         \u001B[0my_variance\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdataframe\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0miloc\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_idx\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0my_mean\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m**\u001B[0m \u001B[0;36m2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Developer/CP2 Data Analysis/.venv/lib/python3.12/site-packages/pandas/core/generic.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   6292\u001B[0m             \u001B[0;32mand\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_accessors\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   6293\u001B[0m             \u001B[0;32mand\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_info_axis\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_can_hold_identifiers_and_holds_name\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   6294\u001B[0m         \u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   6295\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 6296\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mobject\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__getattribute__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m: 'Series' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "\n",
    "# This is the function that we will use to calculate the r squared value for the data. \n",
    "# It uses index column 0 and x and 1 as y where we use x to predict y. \n",
    "# the function goes calculate_r_squared(dataframe, x_idx, y_idx) where x_idx and y_idx are the index of the columns \n",
    "# that we want to use to calculate the r squared value. \n",
    "calculate_r_squared(demo, 1, 2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T15:25:18.402211Z",
     "start_time": "2024-03-06T15:25:18.385051Z"
    }
   },
   "execution_count": 29
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
